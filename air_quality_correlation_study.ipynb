{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "933e22f5",
   "metadata": {},
   "source": [
    "# Air Quality — In‑Depth Correlation Analysis\n",
    "This notebook focuses on **meteorological variables (T, RH, AH)** versus **pollutants** (CO, NOx, NO2, C6H6, NMHC). It provides Pearson/Spearman matrices, partial correlations, diurnal (hour-of-day) correlations, deseasonalized correlations, lagged cross-correlations, and pairwise scatter plots with binned trend overlays.\n",
    "\n",
    "**Notes**: The loader handles the UCI CSV format (semicolon; decimal commas; time like `18.00.00`). Sentinel `-200` values are treated as missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227fa655",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "\n",
    "def safe_display(name: str, dataframe: pd.DataFrame, head_n: int = 20):\n",
    "    try:\n",
    "        from ace_tools import display_dataframe_to_user\n",
    "        display_dataframe_to_user(name, dataframe)\n",
    "    except Exception:\n",
    "        print(f\"\\n=== {name} ===\")\n",
    "        try:\n",
    "            from IPython.display import display\n",
    "            display(dataframe.head(head_n))\n",
    "        except Exception:\n",
    "            print(dataframe.head(head_n).to_string())\n",
    "\n",
    "def robust_read_air_quality(csv_path: str) -> pd.DataFrame:\n",
    "    import pandas as pd, numpy as np\n",
    "    df = None\n",
    "    for kwargs in [\n",
    "        dict(sep=';', decimal=',', engine='python', encoding='utf-8', na_values=[-200, 'NaN', 'NA']),\n",
    "        dict(sep=';', decimal=',', engine='python', encoding='latin-1', na_values=[-200, 'NaN', 'NA']),\n",
    "        dict(sep=None, engine='python', encoding='utf-8', na_values=[-200, 'NaN', 'NA']),\n",
    "        dict(sep=None, engine='python', encoding='latin-1', na_values=[-200, 'NaN', 'NA']),\n",
    "    ]:\n",
    "        try:\n",
    "            df = pd.read_csv(csv_path, **kwargs)\n",
    "            break\n",
    "        except Exception:\n",
    "            df = None\n",
    "    if df is None:\n",
    "        raise RuntimeError(\"Could not read CSV at \" + csv_path)\n",
    "\n",
    "    df = df.loc[:, ~df.columns.astype(str).str.startswith(\"Unnamed\")]\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "    time_cols = [c for c in df.columns if c.lower().startswith('time')]\n",
    "    if len(time_cols) > 0:\n",
    "        tcol = time_cols[0]\n",
    "        df[tcol] = df[tcol].astype(str).str.replace('.', ':', regex=False)\n",
    "\n",
    "    date_cols = [c for c in df.columns if c.lower().startswith('date')]\n",
    "    if date_cols and time_cols:\n",
    "        dt = pd.to_datetime(\n",
    "            df[date_cols[0]].astype(str).str.strip() + ' ' + df[time_cols[0]].astype(str).str.strip(),\n",
    "            dayfirst=True, errors='coerce'\n",
    "        )\n",
    "    elif date_cols:\n",
    "        dt = pd.to_datetime(df[date_cols[0]].astype(str), dayfirst=True, errors='coerce')\n",
    "    else:\n",
    "        dt = pd.to_datetime(df.iloc[:, 0].astype(str) + ' ' + df.iloc[:, 1].astype(str),\n",
    "                            dayfirst=True, errors='coerce')\n",
    "    df.insert(0, 'Datetime', dt)\n",
    "    df = df.dropna(subset=['Datetime']).sort_values('Datetime').set_index('Datetime')\n",
    "\n",
    "    non_numeric = set(date_cols + time_cols)\n",
    "    for col in df.columns:\n",
    "        if col not in non_numeric:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    num_cols = df.select_dtypes(include=['number']).columns\n",
    "    df[num_cols] = df[num_cols].replace(-200, np.nan)\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "    return df\n",
    "\n",
    "CSV_PATH = r\"/mnt/data/AirQualityUCI.csv\"\n",
    "df = robust_read_air_quality(CSV_PATH)\n",
    "\n",
    "pollutant_cols = [c for c in ['CO(GT)', 'NMHC(GT)', 'C6H6(GT)', 'NOx(GT)', 'NO2(GT)'] if c in df.columns]\n",
    "met_cols       = [c for c in ['T', 'RH', 'AH'] if c in df.columns]\n",
    "\n",
    "print(f\"Loaded: {len(df):,} rows, {df.shape[1]} columns; range: {df.index.min()} → {df.index.max()}\")\n",
    "safe_display(\"Detected pollutants / meteorological variables\",\n",
    "             pd.DataFrame({'pollutants':['; '.join(pollutant_cols)], 'meteorology':['; '.join(met_cols)]}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d9e860",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "\n",
    "def pairwise_clean(x: pd.Series, y: pd.Series):\n",
    "    m = ~(x.isna() | y.isna())\n",
    "    return x[m].astype(float).values, y[m].astype(float).values\n",
    "\n",
    "def corr_coef(x, y, method='pearson'):\n",
    "    if len(x) < 3 or len(y) < 3:\n",
    "        return np.nan\n",
    "    if method == 'pearson':\n",
    "        return float(np.corrcoef(x, y)[0,1])\n",
    "    elif method == 'spearman':\n",
    "        xr = pd.Series(x).rank(method='average').values\n",
    "        yr = pd.Series(y).rank(method='average').values\n",
    "        return float(np.corrcoef(xr, yr)[0,1])\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported method\")\n",
    "\n",
    "def fisher_ci(r, n, alpha=0.05):\n",
    "    if np.isnan(r) or n < 4:\n",
    "        return (np.nan, np.nan)\n",
    "    z = np.arctanh(np.clip(r, -0.999999, 0.999999))\n",
    "    se = 1 / np.sqrt(n - 3)\n",
    "    z_lo = z - 1.96*se\n",
    "    z_hi = z + 1.96*se\n",
    "    return (np.tanh(z_lo), np.tanh(z_hi))\n",
    "\n",
    "def partial_corr_xy_given_Z(df_in, x, y, Z):\n",
    "    cols = [x, y] + Z\n",
    "    d = df_in[cols].dropna()\n",
    "    if d.shape[0] < len(cols) + 3:\n",
    "        return np.nan\n",
    "    X = d[Z].values\n",
    "    X = np.c_[np.ones(len(X)), X]\n",
    "    beta_x, *_ = np.linalg.lstsq(X, d[x].values, rcond=None)\n",
    "    e_x = d[x].values - X @ beta_x\n",
    "    beta_y, *_ = np.linalg.lstsq(X, d[y].values, rcond=None)\n",
    "    e_y = d[y].values - X @ beta_y\n",
    "    return float(np.corrcoef(e_x, e_y)[0,1])\n",
    "\n",
    "def hourly_corr(x: pd.Series, y: pd.Series, method='pearson'):\n",
    "    out = {}\n",
    "    for h in range(24):\n",
    "        xv = x[x.index.hour==h]\n",
    "        yv = y[y.index.hour==h]\n",
    "        a, b = pairwise_clean(xv, yv)\n",
    "        out[h] = corr_coef(a, b, method=method)\n",
    "    return pd.Series(out).sort_index()\n",
    "\n",
    "def deseason_hour_month(s: pd.Series):\n",
    "    s1 = s - s.groupby(s.index.hour).transform('mean')\n",
    "    s2 = s1 - s1.groupby(s1.index.month).transform('mean')\n",
    "    return s2\n",
    "\n",
    "def crosscorr_series(x: pd.Series, y: pd.Series, max_lag=72):\n",
    "    lags = np.arange(-max_lag, max_lag+1)\n",
    "    vals = []\n",
    "    for lag in lags:\n",
    "        if lag > 0:\n",
    "            a = x.iloc[:-lag]; b = y.iloc[lag:]\n",
    "        elif lag < 0:\n",
    "            a = x.iloc[-lag:]; b = y.iloc[:lag]\n",
    "        else:\n",
    "            a = x; b = y\n",
    "        ab = pd.concat([a, b], axis=1).dropna()\n",
    "        vals.append(np.corrcoef(ab.iloc[:,0], ab.iloc[:,1])[0,1] if ab.shape[0]>=10 else np.nan)\n",
    "    return lags, np.array(vals, dtype=float)\n",
    "\n",
    "def build_corr_matrix(df, mets, pols, method='pearson'):\n",
    "    mat = pd.DataFrame(index=mets, columns=pols, dtype=float)\n",
    "    for m in mets:\n",
    "        for p in pols:\n",
    "            a, b = pairwise_clean(df[m], df[p])\n",
    "            mat.loc[m, p] = corr_coef(a, b, method=method)\n",
    "    return mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620dec56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) Pearson & Spearman (meteorology × pollutants)\n",
    "pearson_mat = build_corr_matrix(df, met_cols, pollutant_cols, method='pearson')\n",
    "spearman_mat = build_corr_matrix(df, met_cols, pollutant_cols, method='spearman')\n",
    "\n",
    "safe_display(\"Pearson correlation (met × pollutants)\", pearson_mat.round(3))\n",
    "safe_display(\"Spearman correlation (met × pollutants)\", spearman_mat.round(3))\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(pearson_mat.values, interpolation='nearest', aspect='auto')\n",
    "plt.xticks(range(len(pollutant_cols)), pollutant_cols, rotation=45, ha='right')\n",
    "plt.yticks(range(len(met_cols)), met_cols)\n",
    "plt.title('Pearson correlation heatmap (met × pollutants)')\n",
    "plt.colorbar(); plt.tight_layout(); plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(spearman_mat.values, interpolation='nearest', aspect='auto')\n",
    "plt.xticks(range(len(pollutant_cols)), pollutant_cols, rotation=45, ha='right')\n",
    "plt.yticks(range(len(met_cols)), met_cols)\n",
    "plt.title('Spearman correlation heatmap (met × pollutants)')\n",
    "plt.colorbar(); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1f5c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2) Confidence intervals with Fisher z (per pollutant)\n",
    "for p in pollutant_cols:\n",
    "    vals, lows, highs, labels = [], [], [], []\n",
    "    for m in met_cols:\n",
    "        a, b = pairwise_clean(df[m], df[p])\n",
    "        r = corr_coef(a, b, method='pearson')\n",
    "        lo, hi = fisher_ci(r, len(a))\n",
    "        vals.append(r); lows.append(r-lo if not np.isnan(lo) else np.nan); highs.append(hi-r if not np.isnan(hi) else np.nan)\n",
    "        labels.append(m)\n",
    "    x = np.arange(len(labels)); yerr = [np.array(lows), np.array(highs)]\n",
    "    plt.figure(); plt.errorbar(x, vals, yerr=yerr, fmt='o', capsize=3)\n",
    "    plt.xticks(x, labels); plt.title(f'Pearson r with 95% CI — {p} vs meteorology')\n",
    "    plt.ylabel('r'); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d06e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3) Partial correlations (control for other two meteorological vars)\n",
    "rows = []\n",
    "for p in pollutant_cols:\n",
    "    # T | RH, AH\n",
    "    r_t = partial_corr_xy_given_Z(df[[p] + met_cols], 'T', p, [v for v in met_cols if v != 'T']) if 'T' in met_cols else np.nan\n",
    "    r_rh = partial_corr_xy_given_Z(df[[p] + met_cols], 'RH', p, [v for v in met_cols if v != 'RH']) if 'RH' in met_cols else np.nan\n",
    "    r_ah = partial_corr_xy_given_Z(df[[p] + met_cols], 'AH', p, [v for v in met_cols if v != 'AH']) if 'AH' in met_cols else np.nan\n",
    "    rows.append({'pollutant': p, 'T|RH,AH': r_t, 'RH|T,AH': r_rh, 'AH|T,RH': r_ah})\n",
    "partial_df = pd.DataFrame(rows).set_index('pollutant').T\n",
    "safe_display(\"Partial correlations (met ↔ pollutant | others)\", partial_df.round(3))\n",
    "\n",
    "plt.figure(); plt.imshow(partial_df.values, interpolation='nearest', aspect='auto')\n",
    "plt.xticks(range(len(partial_df.columns)), partial_df.columns, rotation=45, ha='right')\n",
    "plt.yticks(range(len(partial_df.index)), partial_df.index)\n",
    "plt.title('Partial correlation heatmap'); plt.colorbar(); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c36a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4) Hour-of-day correlations\n",
    "for p in pollutant_cols:\n",
    "    plt.figure()\n",
    "    styles = ['-', '--', '-.']\n",
    "    for i, m in enumerate(met_cols):\n",
    "        series = hourly_corr(df[m], df[p], method='pearson')\n",
    "        plt.plot(series.index.values, series.values, linestyle=styles[i % len(styles)], label=m)\n",
    "    plt.title(f'Hour-of-day Pearson r — meteorology vs {p}')\n",
    "    plt.xlabel('Hour of day'); plt.ylabel('r'); plt.legend(); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f764bccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5) Deseasonalized correlations (remove hour + month cycles)\n",
    "deseason_df = df.copy()\n",
    "for col in pollutant_cols + met_cols:\n",
    "    deseason_df[col] = deseason_hour_month(df[col])\n",
    "\n",
    "pearson_deseason = build_corr_matrix(deseason_df, met_cols, pollutant_cols, method='pearson')\n",
    "safe_display(\"Pearson correlation after deseasonalization\", pearson_deseason.round(3))\n",
    "\n",
    "plt.figure(); plt.imshow(pearson_deseason.values, interpolation='nearest', aspect='auto')\n",
    "plt.xticks(range(len(pollutant_cols)), pollutant_cols, rotation=45, ha='right')\n",
    "plt.yticks(range(len(met_cols)), met_cols)\n",
    "plt.title('Pearson heatmap — deseasonalized'); plt.colorbar(); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0fba78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6) Lagged cross-correlations (±72 h)\n",
    "for p in pollutant_cols:\n",
    "    plt.figure()\n",
    "    styles = ['-', '--', '-.']\n",
    "    for i, m in enumerate(met_cols):\n",
    "        lags, vals = crosscorr_series(df[m], df[p], max_lag=72)\n",
    "        plt.plot(lags, vals, linestyle=styles[i % len(styles)], label=m)\n",
    "    plt.title(f'Lagged cross-correlation (±72 h): met vs {p}')\n",
    "    plt.xlabel('Lag (hours) — positive: pollutant follows met'); plt.ylabel('r')\n",
    "    plt.legend(); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6643e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 7) Scatter with binned trend overlays (every met × pollutant pair)\n",
    "def scatter_with_binned_trend(x: pd.Series, y: pd.Series, xlab: str, ylab: str, title: str, q: int = 20):\n",
    "    ab = pd.concat([x, y], axis=1).dropna()\n",
    "    if ab.shape[0] == 0:\n",
    "        return\n",
    "    xv = ab.iloc[:,0].values; yv = ab.iloc[:,1].values\n",
    "    plt.figure(); plt.scatter(xv, yv, s=6, alpha=0.4)\n",
    "    try:\n",
    "        bins = pd.qcut(ab.iloc[:,0], q=q, duplicates='drop')\n",
    "        centers = ab.groupby(bins).apply(lambda d: pd.Series({'x_mean': d.iloc[:,0].mean(), 'y_mean': d.iloc[:,1].mean()}))\n",
    "        plt.plot(centers['x_mean'].values, centers['y_mean'].values, linewidth=1.5, marker='o')\n",
    "    except Exception:\n",
    "        pass\n",
    "    plt.xlabel(xlab); plt.ylabel(ylab); plt.title(title); plt.tight_layout(); plt.show()\n",
    "\n",
    "for m in met_cols:\n",
    "    for p in pollutant_cols:\n",
    "        scatter_with_binned_trend(df[m], df[p], m, p, f'{m} vs {p}')\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
